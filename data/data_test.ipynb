{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对数据预处理和加载的测试文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils\n",
    "from skimage import io, transform ,exposure\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取xml文件测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Non-ASCII character '\\xe7' in file vis.py on line 6, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details (vis.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"vis.py\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    #编写一个可以展示图片以及目标边界框的函数\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Non-ASCII character '\\xe7' in file vis.py on line 6, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details\n"
     ]
    }
   ],
   "source": [
    "from vis import show_groundBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from readxml import readxml\n",
    "class_list = ['background','person','bird', 'cat', 'cow', 'dog', 'horse', 'sheep','aeroplane', 'bicycle', 'boat', 'bus', 'car', 'motorbike', 'train','bottle', 'chair', 'diningtable', 'pottedplant', 'sofa','tvmonitor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,l = readxml('/home/yxy/dataset/VOCdevkit/VOC2012/Annotations/2007_000027.xml')\n",
    "show_groundBox('/home/yxy/dataset/VOCdevkit/VOC2012/JPEGImages/2007_000027.jpg', classse = c, locations = l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from voc_dataset import VOCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VOC2012_dataset = VOCDataset('/home/yxy/dataset/VOCdevkit/VOC2012/Annotations/','/home/yxy/dataset/VOCdevkit/VOC2012/JPEGImages/')\n",
    "fig = plt.figure(figsize=(8,16))\n",
    "for i in range(len(VOC2012_dataset)):\n",
    "    sample = VOC2012_dataset[i]\n",
    "    print(i, sample['image'].shape)\n",
    "    show_groundBox(sample['image'], sample['class'], sample['location'])\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据变换测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform import RandomCrop, ColorDistortion, Expand, RandomFlip, Rescale, Extend, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = VOCDataset('/home/yxy/dataset/VOCdevkit/VOC2012/Annotations/','/home/yxy/dataset/VOCdevkit/VOC2012/JPEGImages/',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               RandomCrop(),\n",
    "                                               ColorDistortion(0.7),\n",
    "                                               Expand(0.3),\n",
    "                                               RandomFlip(0.4),\n",
    "                                               Rescale(300.), #（python2）                                       \n",
    "                                               Extend(60),\n",
    "                                               ToTensor()\n",
    "                                           ]))\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=5,shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched['image'].size(),sample_batched['class'].size(),sample_batched['location'].size())\n",
    "    for i in range(3):\n",
    "        show_groundBox(sample_batched['image'][i].numpy().transpose((1, 2, 0)),\n",
    "                      sample_batched['class'][i],\n",
    "                      sample_batched['location'][i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
